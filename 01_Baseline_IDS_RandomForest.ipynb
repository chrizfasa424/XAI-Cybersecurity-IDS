{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGTXb967udjE",
        "outputId": "edcb2e9b-6833-4d3d-f4af-e89bfdfb60e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Phase 1: Random Forest Baseline ---\n",
            "--- Data Files Found. Loading... ---\n",
            "--- Data Loading Successful ---\n",
            "Training data shape: (125973, 42)\n",
            "Testing data shape: (22544, 42)\n",
            "------------------------------\n",
            "--- Starting Data Preprocessing ---\n",
            "Categorical features to encode: ['protocol_type', 'service', 'flag']\n",
            "--- Data Preprocessing Complete ---\n",
            "X_train shape after processing: (125973, 122)\n",
            "X_test shape after processing: (22544, 122)\n",
            "------------------------------\n",
            "--- Starting Model Training (Random Forest) ---\n",
            "--- Model Training Complete ---\n",
            "------------------------------\n",
            "--- Starting Model Evaluation ---\n",
            "Model Accuracy: 76.48%\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Normal (0)       0.65      0.97      0.78      9711\n",
            "  Attack (1)       0.97      0.61      0.75     12833\n",
            "\n",
            "    accuracy                           0.76     22544\n",
            "   macro avg       0.81      0.79      0.76     22544\n",
            "weighted avg       0.83      0.76      0.76     22544\n",
            "\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# PHASE 1: BASELINE MODEL (RANDOM FOREST)\n",
        "# ----------------------------------------\n",
        "# This script loads the NSL-KDD dataset, preprocesses it,\n",
        "# and trains a Random Forest classifier to establish\n",
        "# a baseline for our \"AI-Powered Cyber Defense\" project.\n",
        "#\n",
        "# INSTRUCTIONS FOR COLAB:\n",
        "# 1. Click the \"Files\" icon on the left sidebar.\n",
        "# 2. Click \"Upload\" and select 'KDDTrain+.txt' and 'KDDTest+.txt'.\n",
        "# 3. Once uploaded, run this cell.\n",
        "\n",
        "# Step 1: Import All Necessary Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os # Import 'os' to check if files exist\n",
        "\n",
        "print(\"--- Phase 1: Random Forest Baseline ---\")\n",
        "\n",
        "# Step 2: Define Column Names and Load Data\n",
        "# Check if data files are uploaded to the Colab session\n",
        "if not (os.path.exists('KDDTrain+.txt') and os.path.exists('KDDTest+.txt')):\n",
        "    print(\"--- ERROR ---\")\n",
        "    print(\"Please upload 'KDDTrain+.txt' and 'KDDTest+.txt' using the file sidebar on the left.\")\n",
        "    print(\"-\" * 30)\n",
        "else:\n",
        "    print(\"--- Data Files Found. Loading... ---\")\n",
        "    col_names = [\n",
        "        'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
        "        'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
        "        'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
        "        'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
        "        'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
        "        'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
        "        'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
        "        'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
        "        'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
        "        'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "        'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
        "        'dst_host_srv_rerror_rate', 'label', 'difficulty'\n",
        "    ]\n",
        "\n",
        "    # Load the training and testing data\n",
        "    train_data = pd.read_csv('KDDTrain+.txt', header=None, names=col_names)\n",
        "    test_data = pd.read_csv('KDDTest+.txt', header=None, names=col_names)\n",
        "\n",
        "    train_data = train_data.drop('difficulty', axis=1)\n",
        "    test_data = test_data.drop('difficulty', axis=1)\n",
        "\n",
        "    print(\"--- Data Loading Successful ---\")\n",
        "    print(f\"Training data shape: {train_data.shape}\")\n",
        "    print(f\"Testing data shape: {test_data.shape}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "    # Step 3: Data Preprocessing\n",
        "    print(\"--- Starting Data Preprocessing ---\")\n",
        "\n",
        "    # 3a. Label Binarization: 'normal' = 0, 'attack' = 1\n",
        "    train_data['label'] = train_data['label'].apply(lambda x: 0 if x == 'normal' else 1)\n",
        "    test_data['label'] = test_data['label'].apply(lambda x: 0 if x == 'normal' else 1)\n",
        "\n",
        "    # 3b. Identify Categorical Features\n",
        "    categorical_cols = ['protocol_type', 'service', 'flag']\n",
        "    print(f\"Categorical features to encode: {categorical_cols}\")\n",
        "\n",
        "    # 3c. One-Hot Encoding (Combined Train + Test)\n",
        "    combined_data = pd.concat([train_data, test_data], axis=0)\n",
        "    for col in categorical_cols:\n",
        "        dummies = pd.get_dummies(combined_data[col], prefix=col)\n",
        "        combined_data = pd.concat([combined_data, dummies], axis=1)\n",
        "        combined_data.drop(col, axis=1, inplace=True)\n",
        "\n",
        "    # Separate back into train and test\n",
        "    train_processed = combined_data.iloc[:len(train_data)]\n",
        "    test_processed = combined_data.iloc[len(train_data):]\n",
        "\n",
        "    # 3d. Create Final X (Features) and y (Labels)\n",
        "    X_train = train_processed.drop('label', axis=1)\n",
        "    y_train = train_processed['label']\n",
        "    X_test = test_processed.drop('label', axis=1)\n",
        "    y_test = test_processed['label']\n",
        "\n",
        "    # 3e. Align columns (in case of mismatched categories)\n",
        "    X_train_cols = X_train.columns\n",
        "    X_test_cols = X_test.columns\n",
        "\n",
        "    missing_in_test = set(X_train_cols) - set(X_test_cols)\n",
        "    for c in missing_in_test:\n",
        "        X_test[c] = 0\n",
        "\n",
        "    missing_in_train = set(X_test_cols) - set(X_train_cols)\n",
        "    for c in missing_in_train:\n",
        "        X_train[c] = 0\n",
        "\n",
        "    X_test = X_test[X_train_cols]\n",
        "\n",
        "    # 3f. Feature Scaling\n",
        "    # Identify numerical columns (those that weren't one-hot encoded)\n",
        "    numerical_cols = list(set(col_names) - set(categorical_cols) - set(['label', 'difficulty']))\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "    X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "    print(\"--- Data Preprocessing Complete ---\")\n",
        "    print(f\"X_train shape after processing: {X_train.shape}\")\n",
        "    print(f\"X_test shape after processing: {X_test.shape}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "    # Step 4: Model Training (Random Forest)\n",
        "    print(\"--- Starting Model Training (Random Forest) ---\")\n",
        "\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    print(\"--- Model Training Complete ---\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "    # Step 5: Model Evaluation\n",
        "    print(\"--- Starting Model Evaluation ---\")\n",
        "\n",
        "    y_pred = rf_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(\"\\n\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Normal (0)', 'Attack (1)']))\n",
        "    print(\"-\" * 30)"
      ]
    }
  ]
}